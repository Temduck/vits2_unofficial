{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare filelists for LJSpeech dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://github.com/espeak-ng/espeak-ng/blob/master/docs/languages.md\n",
    "dir_data = \"/home/temduck/vits2/datasets/custom_base\"\n",
    "config = \"../config.yaml\"\n",
    "symlink = \"F2\"\n",
    "n_val = 100\n",
    "n_test = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filelists.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters from config file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.hparams import get_hparams_from_file\n",
    "\n",
    "hps = get_hparams_from_file(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset\n",
    "\n",
    "Here `normalized_text` contains numbers in the form of words.\n",
    "\n",
    "**Note**: you may need to replace all `\"|\"` with `\" | \"` in the file `metadata.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_126...</td>\n",
       "      <td>ақтөбе облысының әкімі оңдасын оразалин өнеркә...</td>\n",
       "      <td>ақтөбе облысының әкімі оңдасын оразалин өнеркә...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_725...</td>\n",
       "      <td>Түнде бұрқасын көтеріледі.\\n</td>\n",
       "      <td>түнде бұрқасын көтеріледі.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_246...</td>\n",
       "      <td>елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...</td>\n",
       "      <td>елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_442...</td>\n",
       "      <td>олардың плей-офф кезеңіне шығуға мүмкіндігі зо...</td>\n",
       "      <td>олардың плей-офф кезеңіне шығуға мүмкіндігі зор.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_968...</td>\n",
       "      <td>бұл оқу орындарында жыл сайын түлектерді даярл...</td>\n",
       "      <td>бұл оқу орындарында жыл сайын түлектерді даярл...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_126...   \n",
       "1  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_725...   \n",
       "2  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_246...   \n",
       "3  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_442...   \n",
       "4  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_968...   \n",
       "\n",
       "                                                text  \\\n",
       "0  ақтөбе облысының әкімі оңдасын оразалин өнеркә...   \n",
       "1                       Түнде бұрқасын көтеріледі.\\n   \n",
       "2  елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...   \n",
       "3  олардың плей-офф кезеңіне шығуға мүмкіндігі зо...   \n",
       "4  бұл оқу орындарында жыл сайын түлектерді даярл...   \n",
       "\n",
       "                                     normalized_text cleaned_text  \n",
       "0  ақтөбе облысының әкімі оңдасын оразалин өнеркә...         None  \n",
       "1                         түнде бұрқасын көтеріледі.         None  \n",
       "2  елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...         None  \n",
       "3   олардың плей-офф кезеңіне шығуға мүмкіндігі зор.         None  \n",
       "4  бұл оқу орындарында жыл сайын түлектерді даярл...         None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"../F2.csv\", \n",
    "    index_col=0\n",
    ")\n",
    "data[\"cleaned_text\"] = None\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    f\"{dir_data}/metadata_copy.csv\",\n",
    "    sep=r\"|\",\n",
    "    header=None,\n",
    "    names=[\"file\",\"\", \"text\", \"normalized_text\", \"cleaned_text\"],\n",
    "    index_col=False,\n",
    "    # converter to add .wav to file name\n",
    "    converters={\"file\": lambda x: f\"{symlink}/{x.strip()}.wav\", \"text\": str.strip, \"normalized_text\": str.strip},\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaners\n",
    "\n",
    "It may take a while, so better to preprocess the text and save it to a file in advance.\n",
    "\n",
    "**Note** `phonemize_text` takes the longest time.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokenize_text', 'add_bos_eos']\n",
      "[['phonemize_text'], ['add_spaces']]\n"
     ]
    }
   ],
   "source": [
    "# Get index of tokenize_text\n",
    "text_cleaners = hps.data.text_cleaners\n",
    "\n",
    "token_idx = text_cleaners.index(\"tokenize_text\")\n",
    "token_cleaners = text_cleaners[token_idx:]\n",
    "print(token_cleaners)\n",
    "\n",
    "\n",
    "# Extract phonemize_text\n",
    "def separate_text_cleaners(text_cleaners):\n",
    "    final_list = []\n",
    "    temp_list = []\n",
    "\n",
    "    for cleaner in text_cleaners:\n",
    "        if cleaner == \"phonemize_text\":\n",
    "            if temp_list:\n",
    "                final_list.append(temp_list)\n",
    "            final_list.append([cleaner])\n",
    "            temp_list = []\n",
    "        else:\n",
    "            temp_list.append(cleaner)\n",
    "\n",
    "    if temp_list:\n",
    "        final_list.append(temp_list)\n",
    "\n",
    "    return final_list\n",
    "\n",
    "\n",
    "text_cleaners = text_cleaners[:token_idx]\n",
    "text_cleaners = separate_text_cleaners(text_cleaners)\n",
    "print(text_cleaners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/temduck/anaconda3/envs/vits2/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/temduck/anaconda3/envs/vits2/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning with ['phonemize_text'] ...\n",
      "Cleaning with ['add_spaces'] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_126...</td>\n",
       "      <td>ақтөбе облысының әкімі оңдасын оразалин өнеркә...</td>\n",
       "      <td>ақтөбе облысының әкімі оңдасын оразалин өнеркә...</td>\n",
       "      <td>ɑ q t ɵ b ˈe &lt;space&gt; ˈo b ɫ ə s ə n ə ŋ &lt;space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_725...</td>\n",
       "      <td>Түнде бұрқасын көтеріледі.\\n</td>\n",
       "      <td>түнде бұрқасын көтеріледі.</td>\n",
       "      <td>t u n d ˈe &lt;space&gt; b ʊ ɾ q ˈɑ s ə n &lt;space&gt; k ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_246...</td>\n",
       "      <td>елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...</td>\n",
       "      <td>елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...</td>\n",
       "      <td>e ɫ b ˈɑ s ə &lt;space&gt; n ˈʊ ɾ s ʊ ɫ t ˈɑ n &lt;spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_442...</td>\n",
       "      <td>олардың плей-офф кезеңіне шығуға мүмкіндігі зо...</td>\n",
       "      <td>олардың плей-офф кезеңіне шығуға мүмкіндігі зор.</td>\n",
       "      <td>o ɫ ˈɑ ɾ d ə ŋ &lt;space&gt; p l ˈe j ˈo f f &lt;space&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_968...</td>\n",
       "      <td>бұл оқу орындарында жыл сайын түлектерді даярл...</td>\n",
       "      <td>бұл оқу орындарында жыл сайын түлектерді даярл...</td>\n",
       "      <td>b ˈʊ ɫ &lt;space&gt; ˈo q w &lt;space&gt; ˈo ɾ ə n d ɑ ɾ ə...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_126...   \n",
       "1  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_725...   \n",
       "2  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_246...   \n",
       "3  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_442...   \n",
       "4  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_968...   \n",
       "\n",
       "                                                text  \\\n",
       "0  ақтөбе облысының әкімі оңдасын оразалин өнеркә...   \n",
       "1                       Түнде бұрқасын көтеріледі.\\n   \n",
       "2  елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...   \n",
       "3  олардың плей-офф кезеңіне шығуға мүмкіндігі зо...   \n",
       "4  бұл оқу орындарында жыл сайын түлектерді даярл...   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  ақтөбе облысының әкімі оңдасын оразалин өнеркә...   \n",
       "1                         түнде бұрқасын көтеріледі.   \n",
       "2  елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...   \n",
       "3   олардың плей-офф кезеңіне шығуға мүмкіндігі зор.   \n",
       "4  бұл оқу орындарында жыл сайын түлектерді даярл...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ɑ q t ɵ b ˈe <space> ˈo b ɫ ə s ə n ə ŋ <space...  \n",
       "1  t u n d ˈe <space> b ʊ ɾ q ˈɑ s ə n <space> k ...  \n",
       "2  e ɫ b ˈɑ s ə <space> n ˈʊ ɾ s ʊ ɫ t ˈɑ n <spac...  \n",
       "3  o ɫ ˈɑ ɾ d ə ŋ <space> p l ˈe j ˈo f f <space>...  \n",
       "4  b ˈʊ ɫ <space> ˈo q w <space> ˈo ɾ ə n d ɑ ɾ ə...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text import tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "text_norm = data[\"normalized_text\"].tolist()\n",
    "for cleaners in text_cleaners:\n",
    "    print(f\"Cleaning with {cleaners} ...\")\n",
    "    if cleaners[0] == \"phonemize_text\":\n",
    "        text_norm = tokenizer(text_norm, Vocab, cleaners, language=hps.data.language)\n",
    "    else:\n",
    "        for idx, text in enumerate(text_norm):\n",
    "            temp = tokenizer(text, Vocab, cleaners, language=hps.data.language)\n",
    "            text_norm[idx] = temp\n",
    "\n",
    "data = data.assign(cleaned_text=text_norm)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 59\n",
      "['<pad>', '<unk>', '<bos>', '<eos>', '<space>', '<laugh>', 'ə', 'ɑ', 'n', 't', 'ˈɑ', 'ɾ', 'e', 's', 'ɫ', 'd', 'q', 'j', 'm', 'k', 'ɪ', 'ˈɪ', 'ˈe', 'b', 'ʒ', 'w', 'z', 'ʀ', 'ŋ', 'p', 'ʃ', 'ˈo', 'o', 'ɡ', 'l', '.', ',', 'æ', 'ɵ', 'u', 'ˈʊ', 'v', 'ʊ', 'a', 'x', 'ˈu', 'ˈɵ', 'f', 'ʔ', 'ˈæ', 'ˈa', 'tʃ', ':', ';', '?', '!', 'h', '(en)', '(kk)']\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from utils.task import load_vocab, save_vocab\n",
    "from text.symbols import special_symbols, UNK_ID\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def yield_tokens(cleaned_text: List[str]):\n",
    "    for text in cleaned_text:\n",
    "        yield text.split()\n",
    "\n",
    "\n",
    "text_norm = data[\"cleaned_text\"].tolist()\n",
    "vocab = build_vocab_from_iterator(yield_tokens(text_norm), specials=special_symbols)\n",
    "vocab.set_default_index(UNK_ID)\n",
    "\n",
    "vocab_file = f\"../vocab.txt\"\n",
    "save_vocab(vocab, vocab_file)\n",
    "\n",
    "vocab = load_vocab(vocab_file)\n",
    "print(f\"Size of vocabulary: {len(vocab)}\")\n",
    "print(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token cleaners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_126...</td>\n",
       "      <td>ақтөбе облысының әкімі оңдасын оразалин өнеркә...</td>\n",
       "      <td>ақтөбе облысының әкімі оңдасын оразалин өнеркә...</td>\n",
       "      <td>ɑ q t ɵ b ˈe &lt;space&gt; ˈo b ɫ ə s ə n ə ŋ &lt;space...</td>\n",
       "      <td>2\\t7\\t16\\t9\\t38\\t23\\t22\\t4\\t31\\t23\\t14\\t6\\t13\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_725...</td>\n",
       "      <td>Түнде бұрқасын көтеріледі.\\n</td>\n",
       "      <td>түнде бұрқасын көтеріледі.</td>\n",
       "      <td>t u n d ˈe &lt;space&gt; b ʊ ɾ q ˈɑ s ə n &lt;space&gt; k ...</td>\n",
       "      <td>2\\t9\\t39\\t8\\t15\\t22\\t4\\t23\\t42\\t11\\t16\\t10\\t13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_246...</td>\n",
       "      <td>елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...</td>\n",
       "      <td>елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...</td>\n",
       "      <td>e ɫ b ˈɑ s ə &lt;space&gt; n ˈʊ ɾ s ʊ ɫ t ˈɑ n &lt;spac...</td>\n",
       "      <td>2\\t12\\t14\\t23\\t10\\t13\\t6\\t4\\t8\\t40\\t11\\t13\\t42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_442...</td>\n",
       "      <td>олардың плей-офф кезеңіне шығуға мүмкіндігі зо...</td>\n",
       "      <td>олардың плей-офф кезеңіне шығуға мүмкіндігі зор.</td>\n",
       "      <td>o ɫ ˈɑ ɾ d ə ŋ &lt;space&gt; p l ˈe j ˈo f f &lt;space&gt;...</td>\n",
       "      <td>2\\t32\\t14\\t10\\t11\\t15\\t6\\t28\\t4\\t29\\t34\\t22\\t1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_968...</td>\n",
       "      <td>бұл оқу орындарында жыл сайын түлектерді даярл...</td>\n",
       "      <td>бұл оқу орындарында жыл сайын түлектерді даярл...</td>\n",
       "      <td>b ˈʊ ɫ &lt;space&gt; ˈo q w &lt;space&gt; ˈo ɾ ə n d ɑ ɾ ə...</td>\n",
       "      <td>2\\t23\\t40\\t14\\t4\\t31\\t16\\t25\\t4\\t31\\t11\\t6\\t8\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_126...   \n",
       "1  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_725...   \n",
       "2  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_246...   \n",
       "3  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_442...   \n",
       "4  /Datasets/ISSAI_KazakhTTS2/F2/Audio/inform_968...   \n",
       "\n",
       "                                                text  \\\n",
       "0  ақтөбе облысының әкімі оңдасын оразалин өнеркә...   \n",
       "1                       Түнде бұрқасын көтеріледі.\\n   \n",
       "2  елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...   \n",
       "3  олардың плей-офф кезеңіне шығуға мүмкіндігі зо...   \n",
       "4  бұл оқу орындарында жыл сайын түлектерді даярл...   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  ақтөбе облысының әкімі оңдасын оразалин өнеркә...   \n",
       "1                         түнде бұрқасын көтеріледі.   \n",
       "2  елбасы нұр-сұлтан назарбаев жолаушылар ұшағыны...   \n",
       "3   олардың плей-офф кезеңіне шығуға мүмкіндігі зор.   \n",
       "4  бұл оқу орындарында жыл сайын түлектерді даярл...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  ɑ q t ɵ b ˈe <space> ˈo b ɫ ə s ə n ə ŋ <space...   \n",
       "1  t u n d ˈe <space> b ʊ ɾ q ˈɑ s ə n <space> k ...   \n",
       "2  e ɫ b ˈɑ s ə <space> n ˈʊ ɾ s ʊ ɫ t ˈɑ n <spac...   \n",
       "3  o ɫ ˈɑ ɾ d ə ŋ <space> p l ˈe j ˈo f f <space>...   \n",
       "4  b ˈʊ ɫ <space> ˈo q w <space> ˈo ɾ ə n d ɑ ɾ ə...   \n",
       "\n",
       "                                              tokens  \n",
       "0  2\\t7\\t16\\t9\\t38\\t23\\t22\\t4\\t31\\t23\\t14\\t6\\t13\\...  \n",
       "1  2\\t9\\t39\\t8\\t15\\t22\\t4\\t23\\t42\\t11\\t16\\t10\\t13...  \n",
       "2  2\\t12\\t14\\t23\\t10\\t13\\t6\\t4\\t8\\t40\\t11\\t13\\t42...  \n",
       "3  2\\t32\\t14\\t10\\t11\\t15\\t6\\t28\\t4\\t29\\t34\\t22\\t1...  \n",
       "4  2\\t23\\t40\\t14\\t4\\t31\\t16\\t25\\t4\\t31\\t11\\t6\\t8\\...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text import detokenizer\n",
    "\n",
    "text_norm = data[\"cleaned_text\"].tolist()\n",
    "for idx, text in enumerate(text_norm):\n",
    "    temp = tokenizer(text, vocab, token_cleaners, language=hps.data.language)\n",
    "    assert UNK_ID not in temp, f\"Found unknown symbol:\\n{text}\\n{detokenizer(temp)}\"\n",
    "    text_norm[idx] = temp\n",
    "\n",
    "text_norm = [\"\\t\".join(map(str, text)) for text in text_norm]\n",
    "data = data.assign(tokens=text_norm)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save train, val, test filelists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"file\", \"tokens\"]]\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data_train = data.iloc[n_val + n_test:]\n",
    "data_val = data.iloc[:n_val]\n",
    "data_test = data.iloc[n_val: n_val + n_test]\n",
    "\n",
    "data_train.to_csv(\"../filelists/train.txt\", sep=\"|\", index=False, header=False)\n",
    "data_val.to_csv(\"../filelists/val.txt\", sep=\"|\", index=False, header=False)\n",
    "data_test.to_csv(\"../filelists/test.txt\", sep=\"|\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "\n",
    "test = pd.read_csv(\"filelists/test.txt\", sep=\"|\", names=[\"file\", \"tokens\"])\n",
    "test.file = test.file.apply(lambda x: x.replace(\"/Datasets/ISSAI_KazakhTTS2/\", \"\"))\n",
    "train = pd.read_csv(\"filelists/train.txt\", sep=\"|\", names=[\"file\", \"tokens\"])\n",
    "train.file = train.file.apply(lambda x: x.replace(\"/Datasets/ISSAI_KazakhTTS2/\", \"\"))\n",
    "val = pd.read_csv(\"filelists/val.txt\", sep=\"|\", names=[\"file\", \"tokens\"])\n",
    "val.file = val.file.apply(lambda x: x.replace(\"/Datasets/ISSAI_KazakhTTS2/\", \"\"))\n",
    "\n",
    "train.to_csv(\"filelists/train.txt\", sep=\"|\", index=False, header=False)\n",
    "val.to_csv(\"filelists/val.txt\", sep=\"|\", index=False, header=False)\n",
    "test.to_csv(\"filelists/test.txt\", sep=\"|\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
